{"cells":[{"cell_type":"markdown","metadata":{"id":"8Gr_tUxLd_IT"},"source":["\n","# ResNet18 model\n","### Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xMVD1Ei3d_IV"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import confusion_matrix, classification_report, top_k_accuracy_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","import numpy as np\n","import time\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"fHB4zVMEd_IY"},"source":["### Model Training"]},{"cell_type":"code","source":["# Define transforms for data augmentation\n","train_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(10),\n","    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# Define transforms for validation and test (no augmentation)\n","val_test_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# Load the dataset without transforms\n","folder_path = '/user/5/toubalih/Lab_project_2/Lab_project_S8/updated_png/'\n","dataset = ImageFolder(root=folder_path)\n","\n","# Extract the targets for stratified splitting\n","targets = np.array([sample[1] for sample in dataset.samples])\n","\n","# Calculate dataset sizes\n","train_size = 0.7\n","val_size = 0.15\n","test_size = 0.15\n","\n","# First split: train+val and test\n","train_val_idx, test_idx, y_train_val, y_test = train_test_split(\n","    range(len(targets)), targets, stratify=targets, test_size=test_size, random_state=42)\n","\n","# Calculate the validation size with respect to the remaining data (train+val)\n","val_size_adjusted = val_size / (train_size + val_size)\n","\n","# Second split: train and val\n","train_idx, val_idx, y_train, y_val = train_test_split(\n","    train_val_idx, y_train_val, stratify=y_train_val, test_size=val_size_adjusted, random_state=42)\n","\n","# Create Subsets\n","train_dataset = Subset(dataset, train_idx)\n","val_dataset = Subset(dataset, val_idx)\n","test_dataset = Subset(dataset, test_idx)\n","\n","# Apply transforms to each subset\n","train_dataset.dataset.transform = train_transform\n","val_dataset.dataset.transform = val_test_transform\n","test_dataset.dataset.transform = val_test_transform\n","\n","# Define data loaders\n","batch_size = 64\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","# Define the model architecture (using a pre-trained model like ResNet as an example)\n","model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, len(dataset.classes))\n","\n","# Define loss function, optimizer, and learning rate scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Training loop\n","num_epochs = 10\n","train_losses = []\n","val_losses = []\n","train_accuracies = []\n","val_accuracies = []\n","\n","# Track start time\n","start_time = time.time()\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_train += labels.size(0)\n","        correct_train += (predicted == labels).sum().item()\n","\n","    train_loss = running_loss / len(train_loader)\n","    train_accuracy = correct_train / total_train * 100\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_accuracy)\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    correct_val = 0\n","    total_val = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total_val += labels.size(0)\n","            correct_val += (predicted == labels).sum().item()\n","\n","    val_loss /= len(val_loader)\n","    val_accuracy = correct_val / total_val * 100\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","\n","    # Update learning rate\n","    scheduler.step()\n","\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n","          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n","          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n","\n","# Plot accuracy evolution after training\n","plt.figure(figsize=(10, 5))\n","plt.plot(train_accuracies, label='Train Accuracy')\n","plt.plot(val_accuracies, label='Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Accuracy Evolution')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Final evaluation on the test set\n","model.eval()\n","test_correct = 0\n","test_total = 0\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        test_total += labels.size(0)\n","        test_correct += (predicted == labels).sum().item()\n","\n","test_accuracy = test_correct / test_total * 100\n","print(f\"Final Test Accuracy: {test_accuracy:.2f}%\")\n","\n","# Calculate and print total run time\n","end_time = time.time()\n","total_time = end_time - start_time\n","print(f'Total run time: {total_time:.2f} seconds')"],"metadata":{"id":"T-Er5aJ7eKlG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6_YtLydmd_Ia"},"source":["### Confusion Matrix and Top Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QZ6VDObyd_Ib"},"outputs":[],"source":["\n","# Plot confusion matrix and metrics\n","def plot_confusion_matrix_and_metrics(model, device, data_loader, class_names):\n","    \"\"\"\n","    Generates and plots a confusion matrix and prints classification metrics for the given data.\n","    \"\"\"\n","    model.eval()\n","    true_labels = []\n","    pred_labels = []\n","\n","    with torch.no_grad():\n","        for data, target in data_loader:\n","            data, target = data.to(device), target.to(device)\n","            outputs = model(data)\n","            preds = torch.argmax(outputs, dim=1)\n","            true_labels.extend(target.cpu().numpy())\n","            pred_labels.extend(preds.cpu().numpy())\n","\n","    # Compute the confusion matrix\n","    conf_mat = confusion_matrix(true_labels, pred_labels)\n","    # Compute other classification metrics\n","    class_report = classification_report(true_labels, pred_labels, target_names=class_names)\n","\n","    # Print the classification report\n","    print(\"Classification Report:\")\n","    print(class_report)\n","\n","    # Plot the confusion matrix\n","    plt.figure(figsize=(15, 15))\n","    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","    plt.title('Confusion Matrix for ResNet18')\n","    plt.xlabel('Predicted Labels')\n","    plt.ylabel('True Labels')\n","    plt.show()\n","\n","# Example of how to call the function\n","#plot_confusion_matrix_and_metrics(model, device, test_loader, class_names)\n","\n","# Evaluate model with top-k accuracy\n","def evaluate_model_with_sklearn_top_k(model, device, test_loader, classes, k_list=[1, 5]):\n","    \"\"\"\n","    Evaluates the model on the test set using scikit-learn's top_k_accuracy_score for multiple k values.\n","\n","    Parameters:\n","    - model (torch.nn.Module): The trained model to evaluate.\n","    - device (torch.device): The device (CPU/GPU) on which to perform the evaluation.\n","    - test_loader (torch.utils.data.DataLoader): DataLoader for the test set.\n","    - classes (list): List of all class labels.\n","    - k_list (list): List of top-k values to calculate.\n","\n","    Returns:\n","    - None, prints the average Top-K accuracy for each k in k_list.\n","    \"\"\"\n","    model.eval()  # Ensure the model is in evaluation mode\n","    true_labels = []\n","    all_scores = []\n","\n","    with torch.no_grad():  # Disable gradient computation\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            outputs = model(data)\n","            # Softmax to convert model logits to probabilities\n","            probabilities = torch.softmax(outputs, dim=1)\n","            all_scores.extend(probabilities.cpu().numpy())\n","            true_labels.extend(target.cpu().numpy())\n","\n","    true_labels = np.array(true_labels)\n","    all_scores = np.array(all_scores)  # Shape: (n_samples, n_classes)\n","\n","    # Ensure the labels parameter is correctly handled\n","    labels = np.arange(len(classes))  # Assuming classes correspond to [0, num_classes-1]\n","\n","    for k in k_list:\n","        top_k_accuracy = top_k_accuracy_score(true_labels, all_scores, k=k, labels=labels)\n","        print(f\"Top-{k} Accuracy on Test Set: {top_k_accuracy * 100:.2f}%\")\n","\n","# Example usage\n","evaluate_model_with_sklearn_top_k(model, device, test_loader, class_names, k_list=[1, 5])"]},{"cell_type":"markdown","metadata":{"id":"F51Sp2EHd_Ic"},"source":["### Accuracy and Loss Curve"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ZhqckQHd_Ic"},"outputs":[],"source":["\n","# Create a new figure\n","fig, ax1 = plt.subplots()\n","\n","# Plot training and validation accuracy\n","color = 'tab:blue'\n","ax1.set_xlabel('Epochs')\n","ax1.set_ylabel('Accuracy', color=color)\n","ax1.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy', color=color, marker='o')\n","ax1.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy', linestyle='dashed', color=color, marker='o')\n","ax1.tick_params(axis='y', labelcolor=color)\n","ax1.legend(loc='upper left')\n","ax1.grid(True)\n","\n","# Create a second y-axis to plot training and validation loss\n","ax2 = ax1.twinx()\n","color = 'tab:red'\n","ax2.set_ylabel('Loss', color=color)\n","ax2.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', color=color, marker='x')\n","ax2.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', linestyle='dashed', color=color, marker='x')\n","ax2.tick_params(axis='y', labelcolor=color)\n","ax2.legend(loc='upper right')\n","\n","plt.title('Accuracy and Loss Curve of ResNet(50 dataset)')\n","plt.tight_layout()\n","plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}