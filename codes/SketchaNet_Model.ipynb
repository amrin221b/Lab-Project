{"cells":[{"cell_type":"markdown","metadata":{"id":"VmWQ0VLeeM_s"},"source":["\n","# SketchaNet model\n","### Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0_kFcBwXeM_v"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import confusion_matrix, classification_report, top_k_accuracy_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import os\n","import torch.nn.functional as F\n","import time\n","from sklearn.model_selection import train_test_split\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vB1TkyeWeM_w"},"source":["### Model Training"]},{"cell_type":"code","source":["\n","# Device configuration\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define transforms to preprocess the data with data augmentation\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # Resize images to fit the input size of SketchANet\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(10),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Load the dataset\n","dataset = ImageFolder(root='/user/5/toubalih/Lab_project_2/Lab_project_S8/png/', transform=transform)\n","\n","# Extract the targets for stratified splitting\n","targets = np.array([sample[1] for sample in dataset.samples])\n","\n","# Calculate dataset sizes\n","train_size = 0.7\n","val_size = 0.15\n","test_size = 0.15\n","\n","# First split: train+val and test\n","train_val_idx, test_idx, y_train_val, y_test = train_test_split(\n","    range(len(targets)), targets, stratify=targets, test_size=test_size, random_state=42)\n","\n","# Calculate the validation size with respect to the remaining data (train+val)\n","val_size_adjusted = val_size / (train_size + val_size)\n","\n","# Second split: train and val\n","train_idx, val_idx, y_train, y_val = train_test_split(\n","    train_val_idx, y_train_val, stratify=y_train_val, test_size=val_size_adjusted, random_state=42)\n","\n","# Create Subsets\n","train_dataset = Subset(dataset, train_idx)\n","val_dataset = Subset(dataset, val_idx)\n","test_dataset = Subset(dataset, test_idx)\n","\n","# Define data loaders\n","batch_size = 64\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","class SketchANet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(SketchANet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=15, stride=3)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=5)\n","        self.bn2 = nn.BatchNorm2d(128)\n","        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(256)\n","        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n","        self.bn4 = nn.BatchNorm2d(256)\n","        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n","        self.bn5 = nn.BatchNorm2d(256)\n","        self.conv6 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n","        self.bn6 = nn.BatchNorm2d(512)\n","        self.conv7 = nn.Conv2d(512, 512, kernel_size=1)\n","        self.bn7 = nn.BatchNorm2d(512)\n","        self.fc = nn.Linear(512 * 6 * 6, num_classes)  # Adjusted input size for fc layer\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.max_pool2d(x, 3, 2)\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.max_pool2d(x, 3, 2)\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        x = F.relu(self.bn4(self.conv4(x)))\n","        x = F.relu(self.bn5(self.conv5(x)))\n","        x = F.max_pool2d(x, 3, 2)\n","        x = F.dropout(F.relu(self.bn6(self.conv6(x))), 0.5)\n","        x = F.dropout(F.relu(self.bn7(self.conv7(x))), 0.5)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","        return x\n","\n","# Initialize the model, loss function, and optimizer with weight decay\n","model = SketchANet(num_classes=len(dataset.classes)).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # Add weight decay\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n","\n","# Track start time\n","start_time = time.time()\n","\n","# Train the model with scheduler\n","num_epochs = 50\n","best_val_loss = float('inf')\n","\n","# Track start time\n","start_time = time.time()\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","    for i, (inputs, labels) in enumerate(train_loader):\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","        _, predicted = torch.max(outputs, 1)\n","        total_train += labels.size(0)\n","        correct_train += (predicted == labels).sum().item()\n","\n","    train_accuracy = 100 * correct_train / total_train\n","    scheduler.step()\n","\n","    # Validate the model\n","    model.eval()\n","    val_loss = 0.0\n","    correct_val = 0\n","    total_val = 0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            _, predicted = torch.max(outputs, 1)\n","            total_val += labels.size(0)\n","            correct_val += (predicted == labels).sum().item()\n","\n","    val_accuracy = 100 * correct_val / total_val\n","\n","    # Print training and validation statistics\n","    print(f'Epoch [{epoch+1}/{num_epochs}], '\n","          f'Training Loss: {running_loss / len(train_loader):.4f}, '\n","          f'Training Accuracy: {train_accuracy:.2f}%, '\n","          f'Validation Loss: {val_loss / len(val_loader):.4f}, '\n","          f'Validation Accuracy: {val_accuracy:.2f}%')\n","\n","    # Save the model with the best validation loss\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), 'best_model.pt')\n","\n","print('Finished Training')\n","\n","# Test the model\n","model.load_state_dict(torch.load('best_model.pt'))\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy on test set: {100 * correct / total:.2f}%')\n","\n","# Calculate and print total run time\n","end_time = time.time()\n","total_time = end_time - start_time\n","print(f'Total run time: {total_time:.2f} seconds')\n"],"metadata":{"id":"FB0zBL4MgR2U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AqT18OGVeM_y"},"source":["### Confusion Matrix and Top Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sEyJkGUteM_y"},"outputs":[],"source":["\n","def get_class_names(folder_path):\n","    \"\"\"\n","    Returns a list of class names, where each class name is the name of a folder\n","    containing images of that class.\n","    \"\"\"\n","    class_names = [d for d in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, d))]\n","    class_names.sort()  # Optional: sort the class names alphabetically\n","    return class_names\n","\n","folder_path = '/user/5/toubalih/Lab_project_2/Lab_project_S8/updated_png'\n","class_names = get_class_names(folder_path)\n","print(class_names)\n","\n","def plot_confusion_matrix_and_metrics(model, device, data_loader, class_names):\n","    \"\"\"\n","    Generates and plots a confusion matrix and prints classification metrics for the given data.\n","    \"\"\"\n","    model.eval()\n","    true_labels = []\n","    pred_labels = []\n","\n","    with torch.no_grad():\n","        for data, target in data_loader:\n","            data, target = data.to(device), target.to(device)\n","            outputs = model(data)\n","            preds = torch.argmax(outputs, dim=1)\n","            true_labels.extend(target.cpu().numpy())\n","            pred_labels.extend(preds.cpu().numpy())\n","\n","    # Compute the confusion matrix\n","    conf_mat = confusion_matrix(true_labels, pred_labels)\n","    # Compute other classification metrics\n","    class_report = classification_report(true_labels, pred_labels, target_names=class_names)\n","\n","    # Print the classification report\n","    print(\"Classification Report:\")\n","    print(class_report)\n","\n","    # Plot the confusion matrix\n","    plt.figure(figsize=(10, 10))\n","    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","    plt.title('Confusion Matrix for SketchNet')\n","    plt.xlabel('Predicted Labels')\n","    plt.ylabel('True Labels')\n","    plt.show()\n","\n","plot_confusion_matrix_and_metrics(model, device, test_loader, class_names)\n","\n","def evaluate_model_with_sklearn_top_k(model, device, test_loader, classes, k=5):\n","    \"\"\"\n","    Evaluates the model on the test set using scikit-learn's top_k_accuracy_score.\n","\n","    Parameters:\n","    - model (torch.nn.Module): The trained model to evaluate.\n","    - device (torch.device): The device (CPU/GPU) on which to perform the evaluation.\n","    - test_loader (torch.utils.data.DataLoader): DataLoader for the test set.\n","    - classes (list): List of all class labels.\n","    - k (int): The top-k accuracy to calculate.\n","\n","    Returns:\n","    - None, prints the average Top-K accuracy.\n","    \"\"\"\n","    model.eval()  # Ensure the model is in evaluation mode\n","    true_labels = []\n","    all_scores = []\n","\n","    with torch.no_grad():  # Disable gradient computation\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            outputs = model(data)\n","            probabilities = torch.softmax(outputs, dim=1)\n","            all_scores.extend(probabilities.cpu().numpy())\n","            true_labels.extend(target.cpu().numpy())\n","\n","    true_labels = np.array(true_labels)\n","    all_scores = np.array(all_scores)\n","    labels = np.arange(len(classes))\n","\n","    top_k_accuracy = top_k_accuracy_score(true_labels, all_scores, k=k, labels=labels)\n","    print(f\"Top-{k} Accuracy on Test Set: {top_k_accuracy * 100:.2f}%\")\n","\n","\n","evaluate_model_with_sklearn_top_k(model, device, test_loader, class_names, k=5)\n"]},{"cell_type":"markdown","metadata":{"id":"_BRwtRw1eM_0"},"source":["### Accuracy and Loss Curve"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v7AmpCYseM_1"},"outputs":[],"source":["\n","# Create a new figure\n","fig, ax1 = plt.subplots()\n","\n","# Plot training and validation accuracy\n","color = 'tab:blue'\n","ax1.set_xlabel('Epochs')\n","ax1.set_ylabel('Accuracy', color=color)\n","ax1.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy', color=color, marker='o')\n","ax1.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy', linestyle='dashed', color=color, marker='o')\n","ax1.tick_params(axis='y', labelcolor=color)\n","ax1.legend(loc='upper left')\n","ax1.grid(True)\n","\n","# Create a second y-axis to plot training and validation loss\n","ax2 = ax1.twinx()\n","color = 'tab:red'\n","ax2.set_ylabel('Loss', color=color)\n","ax2.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', color=color, marker='x')\n","ax2.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', linestyle='dashed', color=color, marker='x')\n","ax2.tick_params(axis='y', labelcolor=color)\n","ax2.legend(loc='upper right')\n","\n","plt.title('Accuracy and Loss Curve of sketchNet(50 dataset)')\n","plt.tight_layout()\n","plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"phelma","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}